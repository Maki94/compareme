%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************
% \chapter{Statističko učenje}  %Title of the First Chapter
\mychapter{1}{Uvod}

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


%********************************** %First Section  **************************************
\section{Sta predtavlja statističko učenje?}

Mašinsko učenje je podoblast veštačke intaligencije čiji je cilj konstruisanje
algoritma i računarskih sistema koji su sposobni da se adaptiraju na nove
situacije i uče na osnovu iskustva. Razvijene su različite tehnike učenja za
izvršavanje različitih zadataka. Osnovne tehnike se tiču nadgledanog učenja za
diskreciono donošenje odluka, nadgledanog učenja za kontinuirano predviđanje i
pojačano učenje za sekvencionalno donošenje odluka, kao i nenadgledano učenje.

% Statisticko učenje predstavlja skup različitih alata za razumevanje podata.
% Ovi alati se mogu klasifikovati kao nadgledano ili nenadgledanog učenje.
% Uopšteno govoreći, nadgledanog učenje podrazumeva izgradnju statističkog modela
% za predviđanje ili procenu izlaznih podataka baziranih na jedan ili više ulaza.
% Kod nenadgledanog učenja možemo učiti veze među podacima, kao i njihovu
% strukturu, ali bez ikakov poznatog izlaza unapred. \\

Većina praktičnih problema koristi oblik nadgedanog mašinskog učenja.
Ovaj model se može posmatrati primena nekog algoritma nad skupom ulaznih $X$ i
izlaznih promenljivih $Y$, trening podaci, za učenje mapiranja $Y \ = \ f(X)$.
Cilj je proceniti parametre funkcije $f$ tako da se ova funkcija može primeniti
za nove ulazne podatke $X$ za koje ne znamo izlaz $Y$, test podaci. Podela
nadgledanog učenja:
\begin{itemize}
  \item Klasifikacija: Problem identifikovanja kategorije klase novog
  posmatranja.
  \item Regresija: Problem predikcije kvantitivne vrednosti.
\end{itemize}

Nenadgledano učenje za ulazne podatke $X$ modelira strukture podataka ili
distribuciju podataka bez povratne informacije $Y$. Cil je
uočavanje zajedničkih svojstava podataka. Ovaj oblik učenja možemo svrstati:
\begin{itemize}
  \item Klasterizacija - metod za analizu grupisanja čiji je cilj
  particionisanje ulznih podataka u $k$ klastera.
  \item Asocijacija - metod za generaisanje pravila koja opisuju podatke.
\end{itemize}

Javlja se još jedan oblik mašinskog učenja, polu-nadgledano učenje. Labele su
dodeljene manjim brojem ulaznih podataka. Razlog može biti cena ručnog
procesiranja informacija.

\section{Primer skupa podataka}

Primer koji će pratiti algoritam kroz ovaj rad ...
% TODO Primer skupa podataka

\section{Procena tačnosti modela}

U statistici ne postoji idealan model mašinskog učenje. Nad jednim skupom
podataka jedan metod može bolje od drugih, dok nad drugim skupom podataka može
pokazati gore performanse. \\

Pokušajmo da procenimo $f$ na bazi trening posmatranja
$\{\left(x_1, \ y_1\right), \ \cdots \ , \ \left(x_n, \ y_n\right)\}$,
gde su $y_1, \ \cdots \ , y_n$ kvalitativni izlazi. Najjednostavniji način za
kvantifikovanje tačnosti procene  $\hat{f}$ je stop trening greške, ondost grešaka koje
su napravljenje ako primenimo stopu greške da procenimo $\hat{f}$ trening posmatranja:
$1/n \sum_{i=1}^{n} I(y_i \neq \hat{y_i})$ - training error rate. \\

Gde je $\hat{y_i}$ klasa za koju se vrši predikcija za i-to posmatranje
koristeći $\hat{f}$. I $I(y_i \neq \hat{y_i})$
\begin{equation}
    I=
    \begin{cases}
      1, & \text{if}\ y_i \neq \hat{y_i} \\
      0, & \text{if}\ y_i = \hat{y_i}
    \end{cases}
  \end{equation}
% $\begin{cases}
%   1 & y_i \neq \hat{y_i}  \
%   0 & y_i = \hat{y_i}  \
% \end{cases}$.
Ako je $I\left(y_i \neq \hat{y_i}\right) = 0$, onda je i-to posmatranje
klasifikovano tačno, ako nije onda je pogrešno klasifikovano. Međutim mi smo
najviše zaiteresovani za procenu grešaka koje se javljaju kod test podataka, ne
kod trening podataka. Za procenu stope test greške za posmatranje $\left(x_0, z_0\right)$
je dato sa $Ave\left(I\left(y_i \neq \hat{y_i}\right)\right)$, gde je $\hat{y_0}$
predviđanje klase labele koja je rezltat primene klasifajera nad testom $x_0$.
Dobar klasifajer je onaj za koji je procena stope test grešaka (2.9) malo.

\section{Šta predstavlja klasifikacioni problem?}

% TODO Šta predstavlja klasifikacioni problem?
